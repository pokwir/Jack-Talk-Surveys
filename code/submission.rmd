---
title: "Evaluation Lead case study â€” Cleaning and analyzing survey data"
output: 
  html_document:
    code_folding: show
    theme:
      bg: "#050022"
      fg: rgb(237, 237, 237)
      primary: rgb(241, 89, 35) 
      secondary: rgb(40, 169, 225)
      base_font:
        google: 'PT Sans'
      heading_font:
        google: 'Work Sans'
---

```{r setup, include=FALSE}
if (requireNamespace("thematic")) 
  thematic::thematic_rmd(font = "auto")
```

---
<br>

## Introduction 
The evaluation lead case study is a skills assessment project used to measure candidate's skill levels in: -\
- quantitative and qualitative data collection and analysis, with an emphasis on quantitative skills,\ 
- data analysis using R and other statistical programming languages,\
- data visualization using R and other statistical programming languages,\
- data quality monitoring, data cleaning, coding, analysis, and reporting findings,\
- and communicating results to a non-technical audience.

The project is based on the data for a pre survey and a post survey completed by youth audience members who have viewed a Jack Talk. 
Jack Talks are mental health presentations delivered by young people to young people. Trained and certified youth speakers use the power of personal stories and mental health education to inspire, engage, educate, and equip young people to look out for themselves and their peers.
The pre and post surveys are used to measure the impact of the Jack Talks presentations on the audience.
<br>

## Goal
The goal of this project is to clean and analyze the pre and post survey data to determine the impact of the Jack Talks presentations on the audience according to the instructions provided.
<br>

## Data
The data for this project is available in the [data]() folder. The data is in the form of two csv files: `pre_survey.csv` and `post_survey.csv`. The data is also available in the package given to candidates. Due to the sensitive nature of the data, the data is not available on GitHub.
<br>

## Process
The process for this project is as follows:\
- Read the data into R\
- Clean the data\
- Analyze the data\
- Report the findings

The granular steps for each of these processes are given in the instructions provided to candidates. These are also available in the `instructions` folder.
The codebook also contains annotations for each step in the process. The codebook is available in the `code` folder.
<br>

## Deliverables
The deliverables for this project are:
- A report in the form of an R Markdown document, (This Markdown document)
- A spreadsheet of the cleaned data set in the form of a csv file, (in the `data_output` folder)
- A coding script in the form of an R script including annotations for each step in the process, results for requirements 5 and 6, and additional description or notes required to interpret the project. (in the `code` folder)
<br>
<br>

### Step 1: Data cleaning
The data cleaning process is described in the `data_cleaning codebook` file. The codebook is available in the `code` folder.
The process followed for cleaning the data to conform to the seven dimensions of data quality is described below.
- Completeness - The data is complete. There are no missing values.
- Uniqueness - The data is unique. There are no duplicate values.
- Timeliness - The data is timely. The data is current and up to date.
- Validity - The data is valid. The data conforms to the data types specified in the instructions.
- Accuracy - The data is accurate. The data conforms to the values specified in the instructions.
- Consistency - The data is consistent. The data conforms to the values specified in the instructions.
- Relevance - The data is relevant. The data meets the standards required for the analysis.

#### 1.1 Checking and removing incomplete records from the data set
```{r set_stage, echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE}
# setting the stage
# data paths 
pre <- "/Users/patrickokwir/Desktop/Lighthouse-data-notes/Jack-Talk-Surveys/datasets/CASE STUDY - Livestream pre FY23.csv"
post <- "/Users/patrickokwir/Desktop/Lighthouse-data-notes/Jack-Talk-Surveys/datasets/CASE STUDY - Livestream post FY23.csv"

# reading the data
library(readr)
df_pre <- read.csv(pre, header = TRUE, sep = ",")
df_post <- read.csv(post, header = TRUE, sep = ",")

# return rows where finished = False
incomplete <- (df_pre[df_pre$Finished == FALSE, ])

# remove incomplete records from the data set
# Remove rows where the user did not finish the survey
df_pre <- df_pre[df_pre$Finished != FALSE, ]
count_false_finished <- nrow(df_pre[df_pre$Finished == FALSE, ])
count_true_finished <- nrow(df_pre[df_pre$Finished != FALSE, ])

cat("Number of incomplete records: ", nrow(incomplete), "\n")
cat(count_true_finished, "responses are marked as finished.")

```
There are 8047 datapoints indicated as complete, there are still responses indicated as 'finished' that are not complete.\
From here, removed all incomplete datapoints.

```{r df_pre, echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE}
library(dplyr)

# Filter rows where at least one of the specified columns is blank
blank_rows <- df_pre %>%
  filter(Q1_a == "" |
         Q2_a == "" |
         Q3_a == "" |
         Q4_a == "" |
         id == "")
#count rows
count_blank_rows <- nrow(blank_rows)
cat("There are: ", count_blank_rows, " observations with atleast one blank coloumn value in the dataset")

```

### ggplot2

```{r}
library(ggplot2)

ggplot(mpg, aes(displ, hwy)) +
  geom_point() + geom_smooth()
```

### lattice

```{r}
lattice::show.settings()
```

### base

```{r}
plot(pressure, col = thematic::thematic_get_option("accent"))
```
